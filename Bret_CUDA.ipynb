{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ab442c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.1+cu110'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70dcdbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "# 读取CSV文件\n",
    "df = pd.read_csv('/mnt/mydisk/beijing.csv')\n",
    "\n",
    "# 在第三列添加label属性并将其值设为1\n",
    "df.insert(3, 'label', 1)\n",
    "\n",
    "# 将修改后的数据写入CSV文件\n",
    "df.to_csv('output.csv', index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b977c907",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-d44e73334a9b3470\n",
      "Reusing dataset csv (/root/.cache/huggingface/datasets/csv/default-d44e73334a9b3470/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f14565066f79486abdc90aa0039fb938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 24\n",
      "{'title': '尹力在学习贯彻习近平新时代中国特色社会主义思想主题教育专题党课上强调 推动习近平新时代中国特色社会主义思想在京华大地落地生根形成生动实践 车俊殷勇李秀领魏小东刘伟李小三参加', 'url': 'http://whlyj.beijing.gov.cn/zwgk/xwzx/szfdt//202305/t20230509_3090538.html', 'text': '当前，全市学习贯彻习近平新时代中国特色社会主义思想主题教育正深入开展。5月8日上午，市委书记尹力围绕“为什么学”“学什么”“怎么学”“怎么干”等四个方面，在市委党校为党员干部讲了一堂主题教育专题党课。他强调，要牢牢把握“学思想、强党性、重实践、建新功”的总要求，集中精力抓好理论学习、调查研究、推动发展、检视整改，推动习近平新时代中国特色社会主义思想在京华大地落地生根，形成生动实践，以奋发有为的精神状态和真抓实干的实际行动，努力创造经得起历史和人民检验的实绩。学习贯彻习近平新时代中国特色社会主义思想主题教育中央第一指导组组长车俊，市委副书记、市长殷勇，市人大常委会主任李秀领，市政协主席魏小东，市委副书记刘伟，中央第一指导组副组长李小三参加。从治国理政新理念新思想新战略，到“十个明确”“十四个坚持”“十三个方面成就”，再到构建人类命运共同体等一系列中国主张，尹力引导大家深入思考“为什么学”。他指出，习近平新时代中国特色社会主义思想实现了马克思主义中国化时代化新的飞跃，我们要在“为什么学”上提高政治站位，持续增强学习的思想自觉和行动自觉。习近平新时代中国特色社会主义思想深刻回答了一系列重大时代课题，实现了对中国特色社会主义建设规律认识的新跃升；坚持以“两个结合”推进理论创新，标注了马克思主义发展的新高度；指引新时代实践取得历史性成就，展现出强大的真理力量和实践伟力；为全世界提供了更多中国智慧和中国方案，引领我国日益走近世界舞台中央。有这一思想的科学指引，我们就有了理论灯塔、思想旗帜、行动指南，就能够始终坚持正确方向，不断把党和人民事业发展推向新高度。“风雨不动安如山”般的理想信念、“江山就是人民、人民就是江山”的为民情怀……尹力向大家详细阐述了“学什么”。他指出，习近平新时代中国特色社会主义思想是博大精深、内涵丰富的科学理论体系，我们要在“学什么”上做到全面系统，真正掌握精髓要义。要细学深思坚定不移的理想信念。习近平新时代中国特色社会主义思想之所以感召人、凝聚人，首先就在于其贯穿着浓烈的信仰追求，我们要深刻把握，坚定理想信念，永葆共产党人政治本色。要细学深思真挚深厚的为民情怀。坚持以人民为中心，是习近平新时代中国特色社会主义思想的根本政治立场，我们要自觉向习近平总书记看齐，始终把人民放在心中最高位置，牢牢站稳人民立场，以实际行动换来群众更好的生活。要细学深思守正创新的理论品格。习近平新时代中国特色社会主义思想读起来“解渴”，用起来“好使”，行起来“有效”，秘诀就在于始终坚持实事求是、守正创新。必须深刻领悟贯穿其中的理论创新品格，坚持用马克思主义之“矢”去射新时代中国之“的”，不断以新的理论指导新的实践。要细学深思鲜活管用的科学方法。习近平新时代中国特色社会主义思想是坚持和运用马克思主义世界观和方法论的典范，我们要努力做到娴熟运用，不断以科学思想方法指导做好各方面工作。要细学深思刀刃向内的自我革命精神。如何跳出治乱兴衰的历史周期率，实现长期执政，是我们党始终在思考和实践的重大问题。延安时期，毛泽东同志给出了第一个答案，这就是“让人民来监督政府”。70多年后，习近平总书记又给出了自我革命这第二个答案。我们要保持解决大党独有难题的清醒和坚定，坚持不懈深化自我革命，把自身锻造得更加坚强有力。全面系统学，及时跟进学，深入思考学，联系实际学，尹力向大家系统讲解了“怎么学”。他指出，习近平新时代中国特色社会主义思想是取之不尽、用之不竭的思想宝库，我们要在“怎么学”上掌握科学方法，推动学习不断走深走实。要久久为功往深里走。发扬“挤”和“钻”的精神，坚持原原本本学，读原著、学原文、悟原理；及时跟进学，真正做到常学常新；融会贯通学，在总结溯源、对照比较中，实现全面透彻的理解把握。要下足功夫往心里走。从理论和实践的辩证关系中，把握这一思想的科学性和先进性；从科学社会主义在当代中国焕发的强大生机活力中，感受这一思想的强大真理力量。作为北京的党员干部，更要带着感情学，从北京这些年的巨大发展变化中，不断增进对习近平新时代中国特色社会主义思想的政治认同、思想认同、理论认同、情感认同，真正做到内化于心、外化于行。要持续用力往实里走。发扬理论联系实际的优良学风，坚持目标导向，及时把思想上的所思所悟、所得所获落实到具体的实践当中；坚持问题导向，真正把学习成果转化为发现问题、分析问题、解决问题的方法和举措。要着力抓好调查研究。把学习和调研更加紧密结合起来，聚焦影响和制约首都发展的突出问题、群众反映强烈的急难愁盼问题，把情况摸清楚、把问题想透彻，有针对性拿出破解之策，不断提高运用党的创新理论研究新情况、解决新问题的能力和水平。加强“四个中心”功能建设、提高“四个服务”水平、深化改革开放、用好接诉即办主抓手……尹力结合北京工作实际启发大家“怎么干”。他指出，习近平新时代中国特色社会主义思想为做好各方面工作提供了根本遵循，我们要在“怎么干”上坚持知行合一，把学习成效转化为实实在在的工作业绩。要坚持以高度的政治责任感真抓实干。牢记“看北京首先要从政治上看”的要求，凡事都要从政治上考量、在大局下行事。全市各级党员干部都要旗帜鲜明讲政治，深刻领悟“两个确立”的决定性意义，带头增强“四个意识”、坚定“四个自信”、做到“两个维护”。牢记首都工作关乎“国之大者”，以新时代首都发展为统领，大力加强“四个中心”功能建设、提高“四个服务”水平，更好服务党和国家工作大局。以“时时放心不下”的责任感，统筹发展和安全，着力防范化解各方面风险，坚决为党中央站好岗、放好哨。当前要深刻汲取“4·18”火灾事故教训，压紧压实安全生产责任制，全面深入开展好安全生产和火灾隐患大排查大整治，全力维护首都政治安全和社会大局稳定。尹力指出，要坚持以首善的工作标准真抓实干。从大的目标来讲，北京要力争率先基本实现社会主义现代化；从工作机制来讲，关键是持续完善学习贯彻习近平新时代中国特色社会主义思想的常态化制度机制，健全习近平总书记对北京重要讲话和指示批示督办落实机制，确保不折不扣贯彻落实；从工作态度上来讲，要把追求卓越、争创一流融入到新时代首都发展各领域和全过程，坚持一张蓝图干到底，把北京这座城市建设、发展、管理得更好。要坚持以改革创新、求真务实的工作作风真抓实干。围绕全市中心工作和重点任务，鼓励大胆探索、勇于实践，多形成可复制可推广的经验。认真落实全面深化改革各项任务，最大限度激发发展动力与活力。用好北京科技和人才等优势，扎实推动经济高质量发展，不断提高发展的质量和效益。要坚持以人民为中心的理念真抓实干。聚焦“七有”“五性”，持续用好、抓好接诉即办这个为民服务主抓手，把惠民生、暖民心、顺民意的工作做到群众心坎上。认真落实党员领导干部直接联系群众制度，推进精治共治法治，团结带领群众共同创造美好生活。要坚持以良好的政治生态真抓实干。通过主题教育，进一步从政治、思想、能力、作风、纪律等方面开展党性分析，从根子上找原因和差距，努力补齐自身短板。坚持以严的基调强化正风肃纪，持之以恒纠治“四风”、树立新风，一体推进“三不腐”，为推动新时代首都发展提供坚强保证。市委、市人大常委会、市政府、市政协领导，中央第一指导组成员，市有关部门负责同志，第一批主题教育单位主要负责同志，市委第一批巡回指导组组长，各区主要负责同志，市委党校在校学员代表参加。（祁梦竹 范俊生）', 'label': 1}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# 加载数据集\n",
    "dataset = load_dataset('csv', data_files='/mnt/mydisk/CSTD/output.csv')\n",
    "\n",
    "# 打印数据集大小和第一个样本\n",
    "print(f\"Dataset size: {len(dataset['train'])}\")\n",
    "print(dataset['train'][0])\n",
    "\n",
    "# 构建数据集类\n",
    "# import torch\n",
    "\n",
    "# class MyDataset(torch.utils.data.Dataset):\n",
    "#     def __init__(self, dataset):\n",
    "#         self.dataset = dataset\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.dataset)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         sample = self.dataset[idx]\n",
    "#         text = sample['text']\n",
    "#         label = sample['label']\n",
    "#         return text, label\n",
    "\n",
    "# # 创建数据集对象\n",
    "# my_dataset = MyDataset(dataset['train'])\n",
    "\n",
    "# # 创建数据加载器\n",
    "# data_loader = torch.utils.data.DataLoader(my_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# # 遍历数据加载器\n",
    "# for batch in data_loader:\n",
    "#     texts, labels = batch\n",
    "#     print(texts, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e76095a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device= cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /mnt/mydisk/bert-base-chinese were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 2])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#快速演示\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('device=', device)\n",
    "\n",
    "from transformers import BertModel\n",
    "\n",
    "#加载预训练模型\n",
    "pretrained = BertModel.from_pretrained('/mnt/mydisk/bert-base-chinese')\n",
    "#需要移动到cuda上\n",
    "pretrained.to(device)\n",
    "\n",
    "#不训练,不需要计算梯度\n",
    "for param in pretrained.parameters():\n",
    "    param.requires_grad_(False)\n",
    "\n",
    "\n",
    "#定义下游任务模型\n",
    "class Model(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = torch.nn.Linear(768, 2)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        with torch.no_grad():\n",
    "            out = pretrained(input_ids=input_ids,\n",
    "                             attention_mask=attention_mask,\n",
    "                             token_type_ids=token_type_ids)\n",
    "\n",
    "        out = self.fc(out.last_hidden_state[:, 0])\n",
    "        out = out.softmax(dim=1)\n",
    "        return out\n",
    "\n",
    "\n",
    "model = Model()\n",
    "#同样要移动到cuda\n",
    "model.to(device)\n",
    "\n",
    "#虚拟一批数据,需要把所有的数据都移动到cuda上\n",
    "input_ids = torch.ones(16, 100).long().to(device)\n",
    "attention_mask = torch.ones(16, 100).long().to(device)\n",
    "token_type_ids = torch.ones(16, 100).long().to(device)\n",
    "labels = torch.ones(16).long().to(device)\n",
    "\n",
    "#试算\n",
    "model(input_ids=input_ids,\n",
    "      attention_mask=attention_mask,\n",
    "      token_type_ids=token_type_ids).shape\n",
    "\n",
    "#后面的计算和中文分类完全一样，只是放在了cuda上计算"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3301dbe6",
   "metadata": {},
   "source": [
    "# Start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "12802c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('尹力在学习贯彻习近平新时代中国特色社会主义思想主题教育专题党课上强调 推动习近平新时代中国特色社会主义思想在京华大地落地生根形成生动实践 车俊殷勇李秀领魏小东刘伟李小三参加', 1)\n",
      "('共青团北京市第十五次代表大会开幕 尹力讲话 贺军科殷勇魏小东刘伟出席', 1)\n",
      "('尹力到市轨道交通指挥中心调研时强调 构建立体化现代化城市交通系统 更好满足城市发展和群众出行需求', 1)\n",
      "('“五一”假期首日，尹力殷勇走进火车站、商圈检查安全生产和城市运行保障等工作，并慰问坚守岗位的劳动者！', 1)\n",
      "('“五一”假期北京预计接待游客885万人次 各大热门公园景区基本约满', 1)\n",
      "('市委常委会召开会议 听取全市社会建设工作情况汇报 研究“五一”安全防范和假日相关工作等事项 市委书记尹力主持会议', 1)\n",
      "('市推进全国文化中心建设领导小组会议召开 尹力主持 殷勇出席', 1)\n",
      "('尹力调研中轴线申遗保护工作时强调 让北京这座千年古都焕发出更加蓬勃的时代活力', 1)\n",
      "('本市召开全市领导干部会议 尹力强调 深刻反思汲取教训 时刻保持警钟长鸣 全面开展全市安全生产隐患大排查大整治 殷勇刘伟出席', 1)\n",
      "('平谷桃花节办了30余年 从带货大桃到带火文旅——桃谷花事', 1)\n",
      "('市“两区”工作领导小组召开会议 尹力主持 殷勇刘伟出席', 1)\n",
      "('尹力到市发展改革委、市财政局、市税务局、市统计局调研时强调 把主题教育学习成果转化为推动首都高质量发展实效', 1)\n",
      "('市委常委会召开会议 传达学习习近平总书记重要讲话精神 研究部署全市深入开展主题教育工作等事项 市委书记尹力主持会议', 1)\n",
      "('春季游热度攀升 旅游市场加速复苏', 1)\n",
      "('市委城市工作委员会召开全体会议 尹力主持 殷勇刘伟出席', 1)\n",
      "('书香浸古建 激活城市文化记忆', 1)\n",
      "('博物馆之城 让金名片更加闪耀', 1)\n",
      "('市委常委会召开会议 研究加快推动北京国际科技创新中心建设工作方案等事项 市委书记尹力主持会议', 1)\n",
      "('“文化润疆”打造文化名片 《五星出东方》将在和田驻场演出', 1)\n",
      "('尹力在金融工作座谈会上强调 贯彻落实党的二十大精神 推动首都金融高质量发展 易纲郭树清易会满殷勇参加', 1)\n",
      "('三条文化带 承载古都“城市之魂”', 1)\n",
      "('“中国发展高层论坛2023年年会”北京市招待晚宴举行 尹力致辞 陆昊殷勇刘伟出席', 1)\n",
      "('守护好北京历史文脉的根与魂', 1)\n",
      "('城市副中心大运河游船今春首航 多条航线饱览千年运河风光', 1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch.utils.data as data\n",
    "\n",
    "class CSVDataset(data.Dataset):\n",
    "    def __init__(self, csv_file_path, text_column, label_column):\n",
    "        self.data = pd.read_csv(csv_file_path)\n",
    "        self.text_column = text_column\n",
    "        self.label_column = label_column\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data.iloc[idx][self.text_column]\n",
    "        label = self.data.iloc[idx][self.label_column]\n",
    "        return text, label\n",
    "    \n",
    "\n",
    "dataset = CSVDataset('/mnt/mydisk/CSTD/output.csv', 'title', 'label')\n",
    "len(dataset)\n",
    "for i in dataset:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e59695a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 500]),\n",
       " torch.Size([4, 500]),\n",
       " torch.Size([4, 500]),\n",
       " tensor([1, 1, 1, 1], device='cuda:0'))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "#加载字典和分词工具\n",
    "token = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "\n",
    "\n",
    "def collate_fn(data):\n",
    "    sents = [i[0] for i in data]\n",
    "    labels = [i[1] for i in data]\n",
    "\n",
    "    #编码\n",
    "    data = token.batch_encode_plus(batch_text_or_text_pairs=sents,\n",
    "                                   truncation=True,\n",
    "                                   padding='max_length',\n",
    "                                   max_length=500,\n",
    "                                   return_tensors='pt',\n",
    "                                   return_length=True)\n",
    "\n",
    "    #input_ids:编码之后的数字\n",
    "    #attention_mask:是补零的位置是0,其他位置是1\n",
    "    input_ids = data['input_ids'].to(device)\n",
    "    attention_mask = data['attention_mask'].to(device)\n",
    "    token_type_ids = data['token_type_ids'].to(device)\n",
    "    labels = torch.LongTensor(labels).to(device)\n",
    "\n",
    "    #print(data['length'], data['length'].max())\n",
    "\n",
    "    return input_ids, attention_mask, token_type_ids, labels\n",
    "\n",
    "\n",
    "#数据加载器\n",
    "loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                     batch_size=4,\n",
    "                                     collate_fn=collate_fn,\n",
    "                                     shuffle=True,\n",
    "                                     drop_last=True)\n",
    "\n",
    "for i, (input_ids, attention_mask, token_type_ids,\n",
    "        labels) in enumerate(loader):\n",
    "    break\n",
    "\n",
    "print(len(loader))\n",
    "input_ids.shape, attention_mask.shape, token_type_ids.shape, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1bd44a7c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.723093569278717 0.25\n",
      "5 0.41070568561553955 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/mydisk/miniconda/envs/pytorch/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "#训练\n",
    "optimizer = AdamW(model.parameters(), lr=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "model.train()\n",
    "for i, (input_ids, attention_mask, token_type_ids,\n",
    "        labels) in enumerate(loader):\n",
    "    out = model(input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                token_type_ids=token_type_ids)\n",
    "\n",
    "    loss = criterion(out, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if i % 5 == 0:\n",
    "        out = out.argmax(dim=1)\n",
    "        accuracy = (out == labels).sum().item() / len(labels)\n",
    "\n",
    "        print(i, loss.item(), accuracy)\n",
    "\n",
    "    if i == 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e9d187c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m correct \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m      3\u001b[0m total \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m----> 5\u001b[0m loader_test \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(dataset\u001b[39m=\u001b[39mDataset(\u001b[39m'\u001b[39m\u001b[39mvalidation\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m      6\u001b[0m                                             batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m,\n\u001b[1;32m      7\u001b[0m                                             collate_fn\u001b[39m=\u001b[39mcollate_fn,\n\u001b[1;32m      8\u001b[0m                                             shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m      9\u001b[0m                                             drop_last\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m \u001b[39mfor\u001b[39;00m i, (input_ids, attention_mask, token_type_ids,\n\u001b[1;32m     12\u001b[0m             labels) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(loader_test):\n\u001b[1;32m     13\u001b[0m         \u001b[39mprint\u001b[39m(input_ids, attention_mask, token_type_ids,labels)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "loader_test = torch.utils.data.DataLoader(dataset=Dataset('validation'),\n",
    "                                            batch_size=32,\n",
    "                                            collate_fn=collate_fn,\n",
    "                                            shuffle=True,\n",
    "                                            drop_last=True)\n",
    "\n",
    "for i, (input_ids, attention_mask, token_type_ids,\n",
    "            labels) in enumerate(loader_test):\n",
    "        print(input_ids, attention_mask, token_type_ids,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "275dd1b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 33\u001b[0m\n\u001b[1;32m     28\u001b[0m         total \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(labels)\n\u001b[1;32m     30\u001b[0m     \u001b[39mprint\u001b[39m(correct \u001b[39m/\u001b[39m total)\n\u001b[0;32m---> 33\u001b[0m test()\n",
      "Cell \u001b[0;32mIn[8], line 7\u001b[0m, in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m correct \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m      5\u001b[0m total \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m----> 7\u001b[0m loader_test \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(dataset\u001b[39m=\u001b[39mDataset(\u001b[39m'\u001b[39m\u001b[39mvalidation\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m      8\u001b[0m                                           batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m,\n\u001b[1;32m      9\u001b[0m                                           collate_fn\u001b[39m=\u001b[39mcollate_fn,\n\u001b[1;32m     10\u001b[0m                                           shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     11\u001b[0m                                           drop_last\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     13\u001b[0m \u001b[39mfor\u001b[39;00m i, (input_ids, attention_mask, token_type_ids,\n\u001b[1;32m     14\u001b[0m         labels) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(loader_test):\n\u001b[1;32m     16\u001b[0m     \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m \u001b[39m5\u001b[39m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "#测试\n",
    "def test():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    loader_test = torch.utils.data.DataLoader(dataset=Dataset('validation'),\n",
    "                                              batch_size=32,\n",
    "                                              collate_fn=collate_fn,\n",
    "                                              shuffle=True,\n",
    "                                              drop_last=True)\n",
    "\n",
    "    for i, (input_ids, attention_mask, token_type_ids,\n",
    "            labels) in enumerate(loader_test):\n",
    "\n",
    "        if i == 5:\n",
    "            break\n",
    "\n",
    "        print(i)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model(input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        token_type_ids=token_type_ids)\n",
    "\n",
    "        out = out.argmax(dim=1)\n",
    "        correct += (out == labels).sum().item()\n",
    "        total += len(labels)\n",
    "\n",
    "    print(correct / total)\n",
    "\n",
    "\n",
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
